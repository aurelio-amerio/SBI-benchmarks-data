{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735181ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/ific/a/aamerio/miniforge3/envs/sbibm_data/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sbi_benchmarks import (\n",
    "    make_metadata,\n",
    "    upload_metadata,\n",
    "    upload_dataset,\n",
    "    base_tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d10b00",
   "metadata": {},
   "source": [
    "# metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596401ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"aurelio-amerio/SBI-benchmarks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f557dce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "make_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e962cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_metadata(\"metadata.json\", repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35a019",
   "metadata": {},
   "source": [
    "# upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c62acd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task_name \u001b[38;5;129;01min\u001b[39;00m base_tasks:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mupload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[43m)\u001b[49m   \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lustre/ific.uv.es/ml/ific088/github/SBI-benchmarks-data/sbi_benchmarks/hf_hub.py:14\u001b[39m, in \u001b[36mupload_dataset\u001b[39m\u001b[34m(repo_name, task_name)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupload_dataset\u001b[39m(repo_name, task_name):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     dataset_train, dataset_val, dataset_test, dataset_reference_posterior = \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     dataset_train.push_to_hub(repo_name, config_name=task_name, split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, private=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     17\u001b[39m     dataset_val.push_to_hub(repo_name, config_name=task_name, split=\u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m, private=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lustre/ific.uv.es/ml/ific088/github/SBI-benchmarks-data/sbi_benchmarks/sbi_tasks.py:74\u001b[39m, in \u001b[36mmake_dataset\u001b[39m\u001b[34m(task_name)\u001b[39m\n\u001b[32m     70\u001b[39m num_samples_test = \u001b[32m10_000\u001b[39m\n\u001b[32m     72\u001b[39m num_samples = max_samples + num_samples_val + num_samples_test\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m data_dict, reference_posteriors, true_parameters, observations = \u001b[43mget_task_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m dtype = np.float32\n\u001b[32m     78\u001b[39m xs = data_dict[\u001b[33m\"\u001b[39m\u001b[33mxs\u001b[39m\u001b[33m\"\u001b[39m][: max_samples]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lustre/ific.uv.es/ml/ific088/github/SBI-benchmarks-data/sbi_benchmarks/sbi_tasks.py:48\u001b[39m, in \u001b[36mget_task_data\u001b[39m\u001b[34m(task_name, num_samples)\u001b[39m\n\u001b[32m     45\u001b[39m simulator = task.get_simulator()\n\u001b[32m     47\u001b[39m thetas = prior(num_samples=num_samples)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m xs = \u001b[43msimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m data = {\u001b[33m\"\u001b[39m\u001b[33mthetas\u001b[39m\u001b[33m\"\u001b[39m: thetas.numpy(), \u001b[33m\"\u001b[39m\u001b[33mxs\u001b[39m\u001b[33m\"\u001b[39m: xs.numpy()}\n\u001b[32m     51\u001b[39m reference_posteriors = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sbibm_data/lib/python3.11/site-packages/sbibm/tasks/simulator.py:58\u001b[39m, in \u001b[36mSimulator.__call__\u001b[39m\u001b[34m(self, parameters, **kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_calls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_simulations + requested_simulations > \u001b[38;5;28mself\u001b[39m.max_calls\n\u001b[32m     55\u001b[39m ):\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SimulationBudgetExceeded\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mself\u001b[39m.num_simulations += requested_simulations\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.flatten_data(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sbibm_data/lib/python3.11/site-packages/sbibm/tasks/bernoulli_glm/task.py:97\u001b[39m, in \u001b[36mBernoulliGLM.get_simulator.<locals>.simulator\u001b[39m\u001b[34m(parameters, return_both)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(parameters.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m     95\u001b[39m     \u001b[38;5;66;03m# Simulate GLM\u001b[39;00m\n\u001b[32m     96\u001b[39m     psi = torch.matmul(design_matrix, parameters[b, :])\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     z = \u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     y = (torch.rand(design_matrix.shape[\u001b[32m0\u001b[39m]) < z).float()\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Calculate summary statistics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sbibm_data/lib/python3.11/site-packages/torch/_tensor.py:38\u001b[39m, in \u001b[36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(\n\u001b[32m     36\u001b[39m     f: Callable[Concatenate[_TensorLike, _P], \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     37\u001b[39m ) -> Callable[Concatenate[_TensorLike, _P], \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m: _TensorLike, *args: _P.args, **kwargs: _P.kwargs) -> \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     41\u001b[39m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[32m     42\u001b[39m             sargs = \u001b[38;5;28mself\u001b[39m, *args\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for task_name in base_tasks:\n",
    "    upload_dataset(repo_name, task_name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c079d970",
   "metadata": {},
   "source": [
    "# gw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb79094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2e2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_dir = \"/home/aure/Documents/dataset(1)/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643095d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = torch.load(f\"{gw_dir}/thetas_0.pt\")\n",
    "theta1 = torch.load(f\"{gw_dir}/thetas_1.pt\")\n",
    "theta2 = torch.load(f\"{gw_dir}/thetas_2.pt\")\n",
    "theta3 = torch.load(f\"{gw_dir}/thetas_3.pt\")\n",
    "theta4 = torch.load(f\"{gw_dir}/thetas_4.pt\")\n",
    "theta5 = torch.load(f\"{gw_dir}/thetas_5.pt\")\n",
    "theta6 = torch.load(f\"{gw_dir}/thetas_6.pt\")\n",
    "theta7 = torch.load(f\"{gw_dir}/thetas_7.pt\")\n",
    "theta8 = torch.load(f\"{gw_dir}/thetas_8.pt\")\n",
    "theta9 = torch.load(f\"{gw_dir}/thetas_9.pt\")\n",
    "\n",
    "\n",
    "\n",
    "xs_raw = torch.load(f\"{gw_dir}/xs_0.pt\")\n",
    "xs_raw1 = torch.load(f\"{gw_dir}/xs_1.pt\")\n",
    "xs_raw2 = torch.load(f\"{gw_dir}/xs_2.pt\")\n",
    "xs_raw3 = torch.load(f\"{gw_dir}/xs_3.pt\")\n",
    "xs_raw4 = torch.load(f\"{gw_dir}/xs_4.pt\")\n",
    "xs_raw5 = torch.load(f\"{gw_dir}/xs_5.pt\")\n",
    "xs_raw6 = torch.load(f\"{gw_dir}/xs_6.pt\")\n",
    "xs_raw7 = torch.load(f\"{gw_dir}/xs_7.pt\")\n",
    "xs_raw8 = torch.load(f\"{gw_dir}/xs_8.pt\")\n",
    "xs_raw9 = torch.load(f\"{gw_dir}/xs_9.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = torch.cat([thetas, theta1, theta2, theta3, theta4, theta5, theta6, theta7, theta8, theta9], dim=0)\n",
    "xs_raw = torch.cat([xs_raw, xs_raw1, xs_raw2, xs_raw3, xs_raw4, xs_raw5, xs_raw6, xs_raw7, xs_raw8, xs_raw9], dim=0)\n",
    "\n",
    "\n",
    "thetas = jnp.array(thetas.numpy())\n",
    "xs_raw = jnp.array(xs_raw.numpy())\n",
    "\n",
    "thetas = jax.device_put(thetas, jax.devices(\"cpu\")[0])\n",
    "xs_raw = jax.device_put(xs_raw, jax.devices(\"cpu\")[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d575ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_dict({\"xs\": xs_raw, \"thetas\": thetas})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbibm_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
